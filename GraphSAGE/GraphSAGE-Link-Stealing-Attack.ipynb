{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0874366",
   "metadata": {},
   "source": [
    "# GraphSAGE - Link Stealing Attack\n",
    "> Steal links from GraphSAGE model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57041ae",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc2acde7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "from dgl import DGLGraph\n",
    "from dgl.data import register_data_args\n",
    "from dgl.data import citation_graph as citegrh\n",
    "from dgl.nn.pytorch.conv import SAGEConv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd41d89",
   "metadata": {},
   "source": [
    "#### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc5c7235",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2966b7f9",
   "metadata": {},
   "source": [
    "#### Disable Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a061a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644971f6",
   "metadata": {},
   "source": [
    "## Target Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f3da8",
   "metadata": {},
   "source": [
    "Inductive trained label prediction model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08afb0ea",
   "metadata": {},
   "source": [
    "#### GraphSAGE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "026ed1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout,\n",
    "                 aggregator_type):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type))\n",
    "        # output layer\n",
    "        self.layers.append(SAGEConv(n_hidden, n_classes, aggregator_type)) # activation None\n",
    "\n",
    "        \n",
    "    def forward(self, graph, inputs):\n",
    "        h = self.dropout(inputs)\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(graph, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e115f1b2",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97e43a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, graph, features, labels, nid):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[nid]\n",
    "        labels = labels[nid]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b80736c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    if args['dataset'] == 'cora':\n",
    "        return citegrh.load_cora()\n",
    "    elif args['dataset'] == 'citeseer':\n",
    "        return citegrh.load_citeseer()\n",
    "    elif args['dataset'] == 'pubmed':\n",
    "        return citegrh.load_pubmed()\n",
    "    elif args['dataset'] is not None and args['dataset'].startswith('reddit'):\n",
    "        return RedditDataset(self_loop=('self-loop' in args.dataset))\n",
    "    else:\n",
    "        raise ValueError('Unknown dataset: {}'.format(args.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b08674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args, process_output=False):\n",
    "    # load and preprocess dataset\n",
    "    print('---------Load Dataset----------\\n')\n",
    "\n",
    "    data = load_data(args)\n",
    "    g = data[0]\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    in_feats = features.shape[1]\n",
    "    n_classes = data.num_classes\n",
    "    n_edges = data.graph.number_of_edges()\n",
    "    \n",
    "    print(\"\"\"\\n\\n--------Data statistics--------\n",
    "    \n",
    "  Edges   %d\n",
    "  Classes %d\n",
    "    \n",
    "  Train samples %d\n",
    "  Val samples   %d\n",
    "  Test samples  %d\"\"\" %\n",
    "          (n_edges, n_classes,\n",
    "           train_mask.int().sum().item(),\n",
    "           val_mask.int().sum().item(),\n",
    "           test_mask.int().sum().item()))\n",
    "\n",
    "    if args['gpu'] < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(args['gpu'])\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "        print(\"\\n  Cuda in use\", args['gpu'])\n",
    "\n",
    "    train_nid = train_mask.nonzero().squeeze()\n",
    "    val_nid = val_mask.nonzero().squeeze()\n",
    "    test_nid = test_mask.nonzero().squeeze()\n",
    "\n",
    "    # graph preprocess and calculate normalization factor\n",
    "    g = dgl.remove_self_loop(g)\n",
    "    n_edges = g.number_of_edges()\n",
    "    if cuda:\n",
    "        g = g.int().to(args['gpu'])\n",
    "\n",
    "    # create GraphSAGE model\n",
    "    model = GraphSAGE(in_feats,\n",
    "                      args['n_hidden'],\n",
    "                      n_classes,\n",
    "                      args['n_layers'],\n",
    "                      F.relu,\n",
    "                      args['dropout'],\n",
    "                      args['aggregator_type'])\n",
    "\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    # use optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'], weight_decay=args['weight_decay'])\n",
    "\n",
    "    # initialize graph\n",
    "    dur = []\n",
    "    if process_output:\n",
    "        print(\"\\n\\n--------Training process--------\\n\")\n",
    "    for epoch in range(args['n_epochs']):\n",
    "        model.train()\n",
    "        if epoch >= 3:\n",
    "            t0 = time.time()\n",
    "        # forward\n",
    "        logits = model(g, features)\n",
    "        loss = F.cross_entropy(logits[train_nid], labels[train_nid])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch >= 3:\n",
    "            dur.append(time.time() - t0)\n",
    "\n",
    "        acc = evaluate(model, g, features, labels, val_nid)\n",
    "        if process_output:\n",
    "            print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | Accuracy {:.4f} | \"\n",
    "              \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur), loss.item(),\n",
    "                                            acc, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    print(\"\\n\\n----------Test Result----------\\n\")\n",
    "    acc = evaluate(model, g, features, labels, test_nid)\n",
    "    print(\"Test Accuracy {:.4f}\".format(acc))\n",
    "    \n",
    "    return model, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16db2016",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Load Dataset----------\n",
      "\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "\n",
      "\n",
      "--------Data statistics--------\n",
      "    \n",
      "  Edges   10556\n",
      "  Classes 7\n",
      "    \n",
      "  Train samples 140\n",
      "  Val samples   500\n",
      "  Test samples  1000\n",
      "\n",
      "  Cuda in use 0\n",
      "\n",
      "\n",
      "----------Test Result----------\n",
      "\n",
      "Test Accuracy 0.8200\n"
     ]
    }
   ],
   "source": [
    "# Model Parameter\n",
    "para = {'aggregator_type': 'gcn', \n",
    "        'dataset': 'cora', \n",
    "        'dropout': 0.5, \n",
    "        'gpu': 0, \n",
    "        'lr': 0.01, \n",
    "        'n_epochs': 200, \n",
    "        'n_hidden': 16, \n",
    "        'n_layers': 2, \n",
    "        'weight_decay': 0.0005}\n",
    "\n",
    "target_model, data = main(para)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4dc05",
   "metadata": {},
   "source": [
    "## Attacker Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1e8042",
   "metadata": {},
   "source": [
    "Fully connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64c163a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class FNN(nn.Module):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout):\n",
    "        super(FNN, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "        # input layer\n",
    "        self.layers.append(nn.Linear(in_feats, n_hidden))\n",
    "        # hidden layers\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(Linear(n_hidden, n_hidden))\n",
    "        # output layer\n",
    "        self.layers.append(Linear(n_hidden, n_classes)) # activation None\n",
    "        \n",
    "    def forward(self, graph, inputs):\n",
    "        h = self.dropout(inputs)\n",
    "        for l, layer in enumerate(self.layers):\n",
    "            h = layer(graph, h)\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104cec3",
   "metadata": {},
   "source": [
    "## Link Stealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad0cba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target Model Posterior of one node\n",
    "cora_graph = data[0]\n",
    "features = cora_graph.ndata['feat']\n",
    "labels = cora_graph.ndata['label']\n",
    "val_mask = cora_graph.ndata['val_mask']\n",
    "val_nid = val_mask.nonzero().squeeze()\n",
    "\n",
    "torch.cuda.set_device(0)\n",
    "cora_graph = cora_graph.int().to(0)\n",
    "features = features.cuda()\n",
    "labels = labels.cuda()\n",
    "val_mask = val_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e9dd488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_posterior(model, graph, features, labels, ind):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(graph, features)\n",
    "        logits = logits[ind]\n",
    "        labels = labels[ind]\n",
    "        print(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91060b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4448, -0.8945,  0.9963,  7.3860,  0.0137, -8.8878,  0.1598],\n",
      "       device='cuda:0') tensor(3, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "get_posterior(target_model, cora_graph, features, labels, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bceaf0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
